{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 예시: 프롬프트 + 모델 + 출력 파서\n",
    "\n",
    "가장 기본적이고 일반적인 사용 사례는 prompt 템플릿과 모델을 함께 연결하는 것입니다. 이것이 어떻게 작동하는지 보기 위해, 각 나라별 수도를 물어보는 Chain을 생성해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "CH01-Basic\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿의 활용\n",
    "\n",
    "`PromptTemplate`\n",
    "\n",
    "- 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다\n",
    "- 사용법\n",
    "  - `template`: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 `{}`는 변수를 나타냅니다.\n",
    "  - `input_variables`: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\n",
    "\n",
    "`input_variables`\n",
    "\n",
    "- input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_response  # 스트리밍 출력\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`from_template()` 메소드를 사용하여 PromptTemplate 객체 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"미국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain 생성\n",
    "\n",
    "### LCEL(LangChain Expression Language)\n",
    "\n",
    "![lcel.png](./images/lcel.png)\n",
    "\n",
    "여기서 우리는 LCEL을 사용하여 다양한 구성 요소를 단일 체인으로 결합합니다\n",
    "\n",
    "```\n",
    "chain = prompt | model | output_parser\n",
    "```\n",
    "\n",
    "`|` 기호는 [unix 파이프 연산자](<https://en.wikipedia.org/wiki/Pipeline_(Unix)>)와 유사하며, 서로 다른 구성 요소를 연결하고 한 구성 요소의 출력을 다음 구성 요소의 입력으로 전달합니다.\n",
    "\n",
    "이 체인에서 사용자 입력은 프롬프트 템플릿으로 전달되고, 그런 다음 프롬프트 템플릿 출력은 모델로 전달됩니다. 각 구성 요소를 개별적으로 살펴보면 무슨 일이 일어나고 있는지 이해할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대해 자세하게 설명해주세요.\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0.1)\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['topic'], input_types={}, partial_variables={}, template='{topic} 에 대해 자세하게 설명해주세요.')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x12be39110>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x12c21e9d0>, root_client=<openai.OpenAI object at 0x12be36010>, root_async_client=<openai.AsyncOpenAI object at 0x12b598390>, model_name='gpt-4.1-nano', temperature=0.1, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### invoke() 호출\n",
    "\n",
    "- python 딕셔너리 형태로 입력값을 전달합니다.(키: 값)\n",
    "- invoke() 함수 호출 시, 입력값을 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"인공지능 모델의 학습 원리는 데이터를 이용해 모델이 문제를 해결하는 방법을 배우는 과정입니다. 일반적으로 다음과 같은 단계로 이루어집니다:\\n\\n1. **데이터 수집:** 모델이 학습할 수 있도록 많은 예제 데이터를 준비합니다.\\n2. **모델 설계:** 문제에 맞는 인공지능 구조(예: 신경망)를 만듭니다.\\n3. **학습 과정:** 데이터를 모델에 입력하고, 모델이 내린 예측과 실제 정답을 비교하여 오차를 계산합니다.\\n4. **오차 줄이기:** 오차를 최소화하도록 모델의 내부 파라미터(가중치)를 조정하는 과정을 반복합니다. 이때 주로 '경사 하강법'이라는 방법을 사용합니다.\\n5. **검증 및 개선:** 학습이 잘 되는지 검증 데이터를 통해 확인하고, 필요하면 모델을 개선합니다.\\n\\n이 과정을 통해 인공지능은 주어진 문제에 대해 더 정확하게 예측하거나 판단할 수 있게 됩니다.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 224, 'prompt_tokens': 24, 'total_tokens': 248, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_04d3664870', 'id': 'chatcmpl-CLAchuVldNgpvVlvbI8F3VLv5r7P6', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--183df641-d6b2-4ff1-a282-429de53e43db-0', usage_metadata={'input_tokens': 24, 'output_tokens': 224, 'total_tokens': 248, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 스트리밍을 출력하는 예시 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 질문하신 내용은 파이썬의 IPython 또는 Jupyter Notebook 환경에서 발생하는 특정 객체와 관련된 것으로 보입니다. 구체적으로는:\n",
      "\n",
      "```python\n",
      "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x11a1ae950>>\n",
      "```\n",
      "\n",
      "이 표현은 파이썬 객체의 문자열 표현으로, 두 가지 중요한 정보를 담고 있습니다:\n",
      "\n",
      "1. **`<bound method Kernel.raw_input of ...>`**  \n",
      "   - `bound method`는 특정 객체에 바인딩된(연결된) 메서드를 의미합니다.  \n",
      "   - 즉, `Kernel.raw_input`라는 메서드가 `Kernel` 객체에 연결되어 있다는 의미입니다.  \n",
      "   - 이 메서드는 `Kernel` 클래스 또는 관련 클래스에 정의된 `raw_input`이라는 함수입니다.\n",
      "\n",
      "2. **`<ipykernel.ipkernel.IPythonKernel object at 0x11a1ae950>`**  \n",
      "   - 이 부분은 `IPythonKernel` 클래스의 인스턴스 객체를 나타내며, 메모리 주소 `0x11a1ae950`에 위치해 있음을 보여줍니다.  \n",
      "   - 즉, 이 객체는 Jupyter Notebook 또는 IPython 환경에서 커널을 담당하는 객체입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 좀 더 구체적으로 설명하면:\n",
      "\n",
      "- **`IPythonKernel` 객체**는 Jupyter Notebook의 커널을 구현하는 핵심 객체입니다. 이 객체는 사용자 코드 실행, 입력/출력 처리, 커널과 클라이언트 간 통신 등을 담당합니다.\n",
      "\n",
      "- **`raw_input` 메서드**는 사용자로부터 입력을 받기 위한 함수입니다. 과거 파이썬 2에서는 `raw_input()`이 표준 입력을 받는 함수였고, 파이썬 3에서는 `input()`으로 변경되었지만, 내부 구현이나 커널에서는 여전히 `raw_input`이라는 이름을 사용할 수 있습니다.\n",
      "\n",
      "- **`<bound method ...>`**는 이 `raw_input`이 특정 `Kernel` 인스턴스에 바인딩된 메서드임을 의미하며, 이 상태에서는 아직 호출되지 않은 상태입니다. 만약 `Kernel.raw_input()`처럼 괄호를 붙여 호출하면, 이 메서드가 실행됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 요약\n",
      "\n",
      "- 이 표현은 `IPythonKernel` 객체의 `raw_input` 메서드에 대한 참조를 보여줍니다.\n",
      "- `raw_input`은 사용자로부터 입력을 받는 기능을 수행하는 메서드입니다.\n",
      "- 이 객체는 Jupyter Notebook 또는 IPython 환경에서 커널을 담당하는 핵심 객체입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 참고\n",
      "\n",
      "이 메시지가 출력된 맥락에 따라 의미가 달라질 수 있습니다:\n",
      "\n",
      "- 만약 이 객체를 그냥 출력하거나 변수에 저장했을 때 나타난 것이라면, 해당 메서드 자체를 출력하는 것일 수 있습니다.\n",
      "- 또는 디버깅 과정에서 이 객체의 정보를 확인하는 과정일 수도 있습니다.\n",
      "\n",
      "혹시 더 구체적인 상황이나 코드 예제와 함께 질문해주시면, 더 상세히 설명드릴 수 있습니다!"
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력파서(Output Parser)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chain 에 출력파서를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공지능(AI) 모델의 학습 원리는 데이터를 이용하여 모델이 특정 작업을 수행할 수 있도록 내부 매개변수(가중치와 편향 등)를 조정하는 과정입니다. 이 과정을 좀 더 구체적으로 설명하면 다음과 같습니다.\\n\\n1. **데이터 수집과 준비**  \\n   - 모델이 학습할 수 있도록 다양한 예제(데이터)를 수집합니다.  \\n   - 데이터는 입력과 정답(레이블)으로 구성되어 있으며, 이를 전처리(정규화, 정제, 증강 등)하여 모델이 학습하기 적합한 형태로 만듭니다.\\n\\n2. **모델 구조 설계**  \\n   - 인공신경망, 결정트리, 서포트 벡터 머신 등 다양한 알고리즘 중에서 문제에 적합한 모델 구조를 선택하거나 설계합니다.  \\n   - 예를 들어, 딥러닝에서는 여러 층으로 구성된 신경망 구조를 사용합니다.\\n\\n3. **초기화**  \\n   - 모델의 가중치와 편향을 무작위 또는 특정 규칙에 따라 초기화합니다.\\n\\n4. **순전파(Forward Propagation)**  \\n   - 입력 데이터를 모델에 넣으면, 각 층을 거치면서 계산이 진행됩니다.  \\n   - 이 과정에서 입력이 가중치와 곱해지고, 활성화 함수(예: ReLU, 시그모이드 등)를 통과하여 출력값(예측값)이 생성됩니다.\\n\\n5. **손실 함수 계산**  \\n   - 모델의 예측값과 실제 정답 간의 차이를 손실 함수(loss function)를 통해 계산합니다.  \\n   - 예를 들어, 평균제곱오차(MSE), 교차 엔트로피(cross-entropy) 등이 사용됩니다.\\n\\n6. **역전파(Backpropagation)**  \\n   - 손실 값을 기준으로, 가중치와 편향이 얼마나 잘못 조정되어야 하는지 계산합니다.  \\n   - 체인 룰(Chain Rule)을 이용하여 손실 함수의 기울기(gradient)를 각 가중치에 대해 계산합니다.\\n\\n7. **가중치 업데이트**  \\n   - 계산된 기울기를 이용하여 가중치를 조정합니다.  \\n   - 일반적으로 경사 하강법(Gradient Descent) 또는 그 변형(예: Adam, RMSProp)을 사용하여 가중치를 조금씩 변경합니다.  \\n   - 이 과정은 여러 번 반복됩니다(에포크, epoch).\\n\\n8. **반복과 최적화**  \\n   - 전체 데이터셋을 여러 번 반복하면서(에포크) 모델이 점점 더 정답에 가까워지도록 학습합니다.  \\n   - 학습이 끝나면, 모델은 새로운 데이터에 대해서도 적절한 예측을 할 수 있게 됩니다.\\n\\n9. **검증과 테스트**  \\n   - 학습 과정 중 또는 후에 별도의 검증 데이터셋으로 모델의 성능을 평가하고, 과적합(overfitting)을 방지하기 위해 조정합니다.\\n\\n---\\n\\n### 핵심 개념 정리\\n- **손실 함수**: 모델의 예측과 실제값 간의 차이를 수치로 표현하는 함수.  \\n- **경사 하강법**: 손실 함수를 최소화하기 위해 가중치를 조정하는 최적화 알고리즘.  \\n- **역전파**: 손실 함수의 기울기를 계산하여 가중치를 업데이트하는 과정.  \\n- **에포크**: 전체 학습 데이터를 한 번 모두 사용하는 과정.  \\n- **학습률(learning rate)**: 가중치를 업데이트할 때 이동하는 크기.\\n\\n이러한 과정을 반복하면서 인공지능 모델은 점차 데이터의 패턴을 학습하고, 새로운 데이터에 대해 더 정확한 예측을 할 수 있게 됩니다.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메서드를 사용하여 input을 전달합니다.\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\"}\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다! 질문하신 내용은 파이썬의 IPython 또는 Jupyter Notebook 환경에서 발생하는 특정 객체와 관련된 것으로 보입니다. 구체적으로는:\n",
      "\n",
      "```python\n",
      "<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x11a1ae950>>\n",
      "```\n",
      "\n",
      "이 표현은 파이썬 객체의 문자열 표현으로, 해당 객체의 어떤 속성이나 메서드에 대한 정보를 보여줍니다. 이를 하나씩 분석해보겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. 전체 구조 분석\n",
      "\n",
      "- `<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x11a1ae950>>`\n",
      "\n",
      "이 구조는 두 부분으로 나뉩니다:\n",
      "\n",
      "1. **`<bound method Kernel.raw_input of ...>`**  \n",
      "   - 이는 '바인딩된 메서드(bound method)'를 의미합니다.\n",
      "   - 즉, `Kernel` 클래스의 `raw_input` 메서드가 특정 인스턴스에 바인딩되어 있다는 의미입니다.\n",
      "   \n",
      "2. **`<ipykernel.ipkernel.IPythonKernel object at 0x11a1ae950>`**  \n",
      "   - 이 부분은 `IPythonKernel` 클래스의 인스턴스 객체를 나타내며, 메모리 주소 `0x11a1ae950`에 위치한 객체입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 상세 설명\n",
      "\n",
      "#### a. `IPythonKernel` 객체\n",
      "\n",
      "- `ipykernel.ipkernel.IPythonKernel`은 Jupyter Notebook 또는 IPython 환경에서 사용하는 커널의 핵심 클래스입니다.\n",
      "- 이 객체는 사용자 코드 실행, 셀 실행, 입력 요청 등 커널의 핵심 기능을 담당합니다.\n",
      "- 이 객체는 여러 메서드와 속성을 가지고 있으며, 그중 하나가 `raw_input`입니다.\n",
      "\n",
      "#### b. `raw_input` 메서드\n",
      "\n",
      "- `raw_input`은 과거 파이썬 2에서 사용자로부터 입력을 받기 위해 사용된 함수입니다.\n",
      "- 파이썬 3에서는 `input()`으로 대체되었으며, `raw_input`은 파이썬 2의 함수입니다.\n",
      "- 그러나, 이 경우 `raw_input`은 메서드로서, 커널이 사용자 입력을 처리하는 내부 메서드일 가능성이 높습니다.\n",
      "\n",
      "#### c. 바인딩된 메서드 (Bound Method)\n",
      "\n",
      "- 파이썬에서 클래스의 인스턴스 메서드를 호출할 때, 그 메서드는 '바인딩된 메서드'가 됩니다.\n",
      "- 이는 해당 인스턴스에 묶여 있으며, 호출 시 인스턴스(`self`)를 자동으로 전달합니다.\n",
      "- `Kernel.raw_input`은 `Kernel` 클래스의 `raw_input` 메서드가 특정 인스턴스에 바인딩된 상태임을 의미합니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. 왜 이런 표현이 나오나?\n",
      "\n",
      "이 문자열은 보통 다음과 같은 상황에서 출력됩니다:\n",
      "\n",
      "- 객체의 `repr()` 또는 `str()`을 호출했을 때\n",
      "- 또는, 특정 객체의 속성이나 메서드를 출력했을 때\n",
      "\n",
      "즉, 이 표현은 `raw_input` 메서드 자체를 가리키며, 아직 호출되지 않은 상태임을 보여줍니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. 정리\n",
      "\n",
      "- `<bound method Kernel.raw_input of <ipykernel.ipkernel.IPythonKernel object at 0x11a1ae950>>`는  \n",
      "  `IPythonKernel` 인스턴스에 바인딩된 `raw_input` 메서드를 의미합니다.\n",
      "- 이 메서드는 사용자 입력을 처리하는 내부 함수일 가능성이 높으며, 아직 호출되지 않은 상태입니다.\n",
      "- 이 표현은 디버깅 또는 객체의 속성을 탐색할 때 자주 볼 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 5. 참고 사항\n",
      "\n",
      "- 파이썬 3에서는 `raw_input()` 대신 `input()`을 사용합니다.\n",
      "- 만약 이 객체를 호출하려면, `kernel.raw_input()`처럼 괄호를 붙여 호출해야 합니다.\n",
      "- 이 객체를 호출하지 않고 그냥 출력하면, 위와 같은 문자열이 나타납니다.\n",
      "\n",
      "---\n",
      "\n",
      "혹시 더 구체적인 맥락이나 관련 코드가 있다면 알려주세요. 더 상세하게 설명드릴 수 있습니다!"
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 템플릿을 변경하여 적용\n",
    "\n",
    "- 아래의 프롬프트 내용을 얼마든지 **변경** 하여 테스트 해볼 수 있습니다.\n",
    "- `model_name` 역시 변경하여 테스트가 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 주어진 상황에 맞는 영어 회화를 작성해 주세요.\n",
    "양식은 [FORMAT]을 참고하여 작성해 주세요.\n",
    "\n",
    "#상황:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿을 이용하여 프롬프트를 생성합니다.\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화합니다.\n",
    "model = ChatOpenAI(model_name=\"gpt-4.1-nano\")\n",
    "\n",
    "# 문자열 출력 파서를 초기화합니다.\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 구성합니다.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:  \n",
      "\"Hello! I’d like to order a table for two, please.\"  \n",
      "\"Could I see the menu, please?\"  \n",
      "\"I’d like the grilled chicken with rice, please.\"  \n",
      "\"Can I get that without onions?\"  \n",
      "\"Thank you. Could I also get a glass of water?\"  \n",
      "\n",
      "- 한글 해석:  \n",
      "\"안녕하세요! 두 사람 자리로 예약하고 싶은데요.\"  \n",
      "\"메뉴 좀 보여주시겠어요?\"  \n",
      "\"그릴 치킨과 밥을 주문할게요.\"  \n",
      "\"양파 빼고 부탁드릴 수 있을까요?\"  \n",
      "\"감사합니다. 물 한 잔도 주세요.\"\n"
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻습니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:  \n",
      "\"Hello! I’d like to order a large pepperoni pizza, please.\"  \n",
      "\"Can I also get some extra cheese on that?\"  \n",
      "\"How long will the delivery take?\"  \n",
      "\"Thank you! I’ll be here waiting.\"\n",
      "\n",
      "- 한글 해석:  \n",
      "\"안녕하세요! 대형 페퍼로니 피자를 주문하고 싶은데요.\"  \n",
      "\"여기에 치즈를 더 넣어주실 수 있나요?\"  \n",
      "\"배달이 얼마나 걸릴까요?\"  \n",
      "\"고맙습니다! 여기서 기다릴게요.\""
     ]
    }
   ],
   "source": [
    "# 이번에는 question 을 '미국에서 피자 주문'으로 설정하여 실행합니다.\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
